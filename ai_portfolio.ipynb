{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be58b994-bc68-4166-91d5-282418b78864",
      "metadata": {
        "id": "be58b994-bc68-4166-91d5-282418b78864"
      },
      "source": [
        "# Project: Portfolio - Final Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c1fb239a-1c81-4476-9009-d87abadf9506",
      "metadata": {
        "id": "c1fb239a-1c81-4476-9009-d87abadf9506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63b89f9-f54a-4154-d47c-8021cd4f9b62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4069 images belonging to 5 classes.\n",
            "Found 2058 images belonging to 5 classes.\n",
            "Epoch 1/10\n",
            "127/127 [==============================] - 158s 1s/step - loss: 0.9640 - accuracy: 0.5834 - val_loss: 0.4891 - val_accuracy: 0.8095\n",
            "Epoch 2/10\n",
            "127/127 [==============================] - 151s 1s/step - loss: 0.5590 - accuracy: 0.7855 - val_loss: 0.4657 - val_accuracy: 0.8158\n",
            "Epoch 3/10\n",
            "127/127 [==============================] - 150s 1s/step - loss: 0.4681 - accuracy: 0.8090 - val_loss: 0.3785 - val_accuracy: 0.8260\n",
            "Epoch 4/10\n",
            "127/127 [==============================] - 156s 1s/step - loss: 0.4240 - accuracy: 0.8323 - val_loss: 0.2976 - val_accuracy: 0.8844\n",
            "Epoch 5/10\n",
            "127/127 [==============================] - 151s 1s/step - loss: 0.3856 - accuracy: 0.8390 - val_loss: 0.2610 - val_accuracy: 0.8950\n",
            "Epoch 6/10\n",
            "127/127 [==============================] - 150s 1s/step - loss: 0.3656 - accuracy: 0.8412 - val_loss: 0.2940 - val_accuracy: 0.8780\n",
            "Epoch 7/10\n",
            "127/127 [==============================] - 154s 1s/step - loss: 0.3647 - accuracy: 0.8511 - val_loss: 0.2422 - val_accuracy: 0.8984\n",
            "Epoch 8/10\n",
            "127/127 [==============================] - 150s 1s/step - loss: 0.3372 - accuracy: 0.8578 - val_loss: 0.2541 - val_accuracy: 0.8873\n",
            "Epoch 9/10\n",
            "127/127 [==============================] - 150s 1s/step - loss: 0.3318 - accuracy: 0.8665 - val_loss: 0.3729 - val_accuracy: 0.8377\n",
            "Epoch 10/10\n",
            "127/127 [==============================] - 149s 1s/step - loss: 0.3142 - accuracy: 0.8698 - val_loss: 0.2056 - val_accuracy: 0.9164\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from PIL import ImageFile\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import re\n",
        "\n",
        "# Tentukan direktori sumber dan tujuan\n",
        "data_dir = Path('/content/corn-or-maize-leaf-disease-dataset')\n",
        "train_dir = Path('/content/train')\n",
        "val_dir = Path('/content/val')\n",
        "test_dir = Path('/content/test')\n",
        "\n",
        "# Membuat direktori tujuan jika belum ada\n",
        "for dir_path in [train_dir, val_dir, test_dir]:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "def split_data(data_dir, train_dir, val_dir, test_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
        "    for label_dir in data_dir.iterdir():\n",
        "        if label_dir.is_dir():\n",
        "            # Memuat daftar file di direktori label\n",
        "            files = list(label_dir.glob('*'))\n",
        "            random.shuffle(files)\n",
        "\n",
        "            # Menentukan jumlah file untuk setiap set\n",
        "            train_files = files[:int(len(files) * train_ratio)]\n",
        "            val_files = files[int(len(files) * train_ratio):int(len(files) * (train_ratio + val_ratio))]\n",
        "            test_files = files[int(len(files) * (train_ratio + val_ratio)):]\n",
        "\n",
        "            # Mengganti spasi dengan garis bawah dalam nama label\n",
        "            label_name = label_dir.name.replace(\" \", \"_\")\n",
        "\n",
        "            # Membuat direktori untuk setiap label di dalam direktori tujuan\n",
        "            for dir_path in [train_dir, val_dir, test_dir]:\n",
        "                os.makedirs(dir_path / label_name, exist_ok=True)\n",
        "\n",
        "            # Menyalin file ke set pelatihan\n",
        "            for file in train_files:\n",
        "                try:\n",
        "                    img = Image.open(file)\n",
        "                    img.verify()  # Memastikan file gambar tidak rusak\n",
        "                    new_file_name = re.sub(r'[^a-zA-Z0-9_\\.]', '_', file.name)\n",
        "                    shutil.copy(file, train_dir / label_name / new_file_name)\n",
        "                except (IOError, SyntaxError) as e:\n",
        "                    print(f\"Error copying file {file}: {e}\")\n",
        "\n",
        "            # Menyalin file ke set validasi\n",
        "            for file in val_files:\n",
        "                try:\n",
        "                    img = Image.open(file)\n",
        "                    img.verify()  # Memastikan file gambar tidak rusak\n",
        "                    new_file_name = re.sub(r'[^a-zA-Z0-9_\\.]', '_', file.name)\n",
        "                    shutil.copy(file, val_dir / label_name / new_file_name)\n",
        "                except (IOError, SyntaxError) as e:\n",
        "                    print(f\"Error copying file {file}: {e}\")\n",
        "\n",
        "            # Menyalin file ke set pengujian\n",
        "            for file in test_files:\n",
        "                try:\n",
        "                    img = Image.open(file)\n",
        "                    img.verify()  # Memastikan file gambar tidak rusak\n",
        "                    new_file_name = re.sub(r'[^a-zA-Z0-9_\\.]', '_', file.name)\n",
        "                    shutil.copy(file, test_dir / label_name / new_file_name)\n",
        "                except (IOError, SyntaxError) as e:\n",
        "                    print(f\"Error copying file {file}: {e}\")\n",
        "\n",
        "# Memanggil fungsi untuk membagi data\n",
        "split_data(data_dir, train_dir, val_dir, test_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1)\n",
        "\n",
        "# Menentukan dimensi gambar dan batch size\n",
        "target_size = (150, 150)\n",
        "batch_size = 32\n",
        "\n",
        "# Mengecek apakah folder validation memiliki gambar\n",
        "validation_images = sum(len(files) for _, _, files in os.walk(val_dir))\n",
        "\n",
        "if validation_images == 0:\n",
        "    print(\"Folder validation tidak memiliki gambar.\")\n",
        "    exit()\n",
        "\n",
        "# Augmentasi dan normalisasi data gambar\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Augmentasi data gambar untuk validasi\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Membuat generator gambar untuk data latih\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Membuat generator gambar untuk data validasi\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Tidak perlu untuk di-shuffle\n",
        ")\n",
        "\n",
        "# Perbarui jumlah langkah validasi\n",
        "validation_steps = math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
        "\n",
        "# Membuat model CNN\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(5, activation='softmax')  # 5 kelas\n",
        "])\n",
        "\n",
        "# Kompilasi model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='rmsprop',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Pelatihan model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
